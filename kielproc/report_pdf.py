from __future__ import annotations
from matplotlib.backends.backend_pdf import PdfPages
import json, math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from pathlib import Path


def _load_json(p: Path) -> dict:
    try:
        return json.loads(Path(p).read_text())
    except Exception:
        return {}


def _safe_float(x):
    try:
        return float(x)
    except Exception:
        return None


def _fit_linear_L2(x: np.ndarray, y: np.ndarray, w: np.ndarray | None = None) -> tuple[float, float]:
    """Least-squares fit of y ≈ m*x + c (optionally weighted)."""
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    if w is None:
        w = np.ones_like(x)
    w = np.asarray(w, dtype=float)
    mask = np.isfinite(x) & np.isfinite(y) & np.isfinite(w)
    x = x[mask]
    y = y[mask]
    w = w[mask]
    if x.size < 2:
        xm = float(np.nanmedian(x)) if x.size else 1.0
        ym = float(np.nanmedian(y)) if y.size else 0.0
        m = 0.0 if xm <= 0 else (ym / (2.0 * xm))
        c = ym - m * xm
        return (m, c)
    Sw = float(np.sum(w))
    Sx = float(np.sum(w * x))
    Sy = float(np.sum(w * y))
    Sxx = float(np.sum(w * x * x))
    Sxy = float(np.sum(w * x * y))
    denom = Sw * Sxx - Sx * Sx
    if abs(denom) < 1e-12:
        xm = float(np.average(x, weights=w))
        ym = float(np.average(y, weights=w))
        m = 0.0 if xm <= 0 else (ym / (2.0 * xm))
        c = ym - m * xm
        return (m, c)
    m = (Sw * Sxy - Sx * Sy) / denom
    c = (Sy - m * Sx) / Sw
    m = float(max(m, 0.0))
    c = float(max(c, 0.0))
    return (m, c)


def _compute_errors_over_band(K: float, m: float, c: float, dp_lo: float, dp_hi: float, n: int = 400) -> dict:
    """Compute mean|Δ| and worst|Δ| between 820 (m*dp+c) and UIC (K√dp) across a uniform DP grid."""
    grid = np.linspace(max(0.0, dp_lo), max(dp_lo, dp_hi), num=max(2, n))
    y_uic = K * np.sqrt(np.clip(grid, 0.0, None))
    y_820 = m * grid + c
    err = y_820 - y_uic
    return {
        "mean_abs": float(np.nanmean(np.abs(err))),
        "worst_abs": float(np.nanmax(np.abs(err))),
        "dp_at_worst": float(grid[int(np.nanargmax(np.abs(err)))]),
    }


def _solve_crossover(K: float, m: float, c: float) -> float | None:
    """Solve m*dp + c = K√dp for dp>0."""
    try:
        A = m * m
        B = 2 * m * c - K * K
        Cq = c * c
        disc = B * B - 4 * A * Cq
        if disc < 0:
            return None
        r1 = (-B + math.sqrt(disc)) / (2 * A)
        r2 = (-B - math.sqrt(disc)) / (2 * A)
        for r in (r1, r2):
            if r and r > 0:
                return float(r)
    except Exception:
        return None
    return None


def _fig_text_page(title: str, blocks: list[list[str]]) -> plt.Figure:
    fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait
    ax = fig.add_axes([0, 0, 1, 1])
    ax.axis("off")
    ax.set_title(title, loc="left")
    text = "\n\n".join("\n".join(b) for b in blocks)
    ax.text(0.03, 0.97, text, va="top", ha="left", fontsize=11, family="monospace")
    return fig


def _fig_cover(outdir: Path, summary_path: Path) -> plt.Figure:
    s = {}
    try:
        s = json.loads(Path(summary_path).read_text())
    except Exception:
        pass
    meta_path = Path(outdir) / "transmitter_lookup_meta.json"
    flow_meta = {}
    try:
        flow_meta = json.loads(meta_path.read_text())
    except Exception:
        pass

    fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait
    ax = fig.add_axes([0,0,1,1]); ax.axis("off")
    lines = []
    lines.append("KielProc — Mill PA Differential Validation Report")
    lines.append("")
    lines.append(f"Generated: {datetime.now().isoformat(timespec='seconds')}")
    if s:
        lines.append(f"Site: {s.get('site_name','')}")
        bp = s.get("baro_pa", None)
        if isinstance(bp, (int, float)): lines.append(f"Barometric pressure: {bp:.0f} Pa")
        lines.append(f"Input mode: {s.get('input_mode','')}")
        lines.append(f"Prepared input: {s.get('prepared_input_dir','')}")
        if s.get("beta") is not None or s.get("r") is not None:
            lines.append(f"β: {s.get('beta')}    r: {s.get('r')}")
    if flow_meta:
        cal = flow_meta.get("calibration", {})
        lines.append("")
        lines.append(f"Season: {flow_meta.get('season','')}")
        if cal:
            lines.append(f"UIC K (t/h per √mbar): {cal.get('K_uic','')}")
            lines.append(f"820 m (t/h/mbar): {cal.get('m_820','')}   c (t/h): {cal.get('c_820','')}")
            lines.append(f"Calibration source: {cal.get('source','')}")
    ax.text(0.08, 0.92, "\n".join(lines), va="top", ha="left", fontsize=12, family="monospace")
    ax.text(0.08, 0.06, "Generated by kielproc.run_easy.run_all()", fontsize=9)
    return fig


def _exec_summary(outdir: Path, summary_path: Path) -> plt.Figure:
    s = _load_json(summary_path)
    blocks: list[list[str]] = []
    if s:
        blocks.append([
            "Executive Summary",
            "─────────────────",
            f"Site: {s.get('site_name','')}",
            f"Input mode: {s.get('input_mode','')}",
        ])
    else:
        blocks.append(["Executive Summary", "─────────────────", "No summary available."])

    # Overlay stats (from combined or overlay csv)
    meta = _load_json(Path(outdir) / "transmitter_lookup_meta.json")
    overlay_csv = meta.get("combined_csv") or meta.get("overlay_csv")
    n = 0; dp_min = dp_max = None; mean_abs_err = worst_abs_err = 0.0
    if overlay_csv and Path(overlay_csv).exists():
        try:
            df = pd.read_csv(Path(overlay_csv))
            cand = None
            for name in ["data_DP_mbar", "DP_mbar", "dp_mbar", "dp (mbar)", "dp", "i/p", "differential"]:
                if name in df.columns:
                    cand = name
                    break
            if cand is None:
                for col in df.columns:
                    sdp = pd.to_numeric(df[col], errors="coerce")
                    if sdp.notna().sum() > 0:
                        cand = col
                        break
            if cand:
                dp_series = pd.to_numeric(df[cand], errors="coerce").dropna()
                n = int(dp_series.size)
                if n > 0:
                    dp_min = float(dp_series.min()); dp_max = float(dp_series.max())
                    if "data_Flow_err_820_minus_UIC_tph" in df.columns:
                        err = pd.to_numeric(df["data_Flow_err_820_minus_UIC_tph"], errors="coerce")
                    elif {"data_Flow_820_tph", "data_Flow_UIC_tph"}.issubset(df.columns):
                        err = pd.to_numeric(df["data_Flow_820_tph"], errors="coerce") - pd.to_numeric(df["data_Flow_UIC_tph"], errors="coerce")
                    elif {"Flow_820_tph", "Flow_UIC_tph"}.issubset(df.columns):
                        err = pd.to_numeric(df["Flow_820_tph"], errors="coerce") - pd.to_numeric(df["Flow_UIC_tph"], errors="coerce")
                    else:
                        err = None
                    if err is not None:
                        mean_abs_err = float(np.nanmean(np.abs(err)))
                        worst_abs_err = float(np.nanmax(np.abs(err)))
        except Exception:
            pass

    if n > 0:
        # Piccolo range/avg current (for implied-current check)
        s_all = _load_json(summary_path)
        pic = (s_all.get("piccolo_info") or {})
        rng = pic.get("range_mbar", None)
        avgI = pic.get("avg_current_mA", None)
        impliedI = None
        if rng and dp_min is not None and dp_max is not None and rng > 0:
            I_lo = 4.0 + 16.0 * (dp_min / float(rng))
            I_hi = 4.0 + 16.0 * (dp_max / float(rng))
            impliedI = (I_lo, I_hi)
        blocks.append([
            "Overlay (Piccolo-derived DP):",
            f"  Samples: n = {n}",
            f"  DP band: {dp_min:.3f} – {dp_max:.3f} mbar",
            f"  820 vs UIC error: mean |Δ| = {mean_abs_err:.3f} t/h, worst |Δ| = {worst_abs_err:.3f} t/h",
        ])
        line = []
        if rng:   line.append(f"Range = {rng:.3f} mbar")
        if avgI:  line.append(f"Avg I = {avgI:.4f} mA (workbook)")
        if impliedI: line.append(f"Implied I from overlay = {impliedI[0]:.4f}–{impliedI[1]:.4f} mA")
        if line: blocks.append(["Piccolo mapping: " + " | ".join(line)])

    return _fig_text_page("Executive Summary", blocks)


def _context_and_method(outdir: Path, summary_path: Path) -> plt.Figure:
    blocks = [[
        "Context & Method",
        "────────────────",
        "Comparison of UIC √DP vs 820 linear flow.",
    ]]
    return _fig_text_page("Context & Method", blocks)


def _recommendations_page(outdir: Path, summary_path: Path) -> plt.Figure | None:
    """
    Recommend 820 gain/bias (m*, c*) to best track UIC = K√DP over the operating DP band.
    Operating band:
      • If overlay present: [P5, P95] of overlay DP (robust to outliers).
      • Else: default [2, 6] mbar.
    Fit: weighted least-squares (weights = 1 or overlay histogram density).
    """
    meta = _load_json(Path(outdir) / "transmitter_lookup_meta.json")
    if not meta:
        return None
    cal = meta.get("calibration", {}) or {}
    K = _safe_float(cal.get("K_uic"))
    m0 = _safe_float(cal.get("m_820"))
    c0 = _safe_float(cal.get("c_820"))
    if not (K and K > 0):
        return None

    overlay_csv = meta.get("overlay_csv", None)
    dp = None
    if overlay_csv and Path(overlay_csv).exists():
        try:
            d = pd.read_csv(Path(overlay_csv))
            cand = None
            for name in ["DP_mbar", "dp_mbar", "dp (mbar)", "dp", "i/p", "differential", "data_DP_mbar"]:
                if name in d.columns:
                    cand = name
                    break
            if cand is None:
                for col in d.columns:
                    s = pd.to_numeric(d[col], errors="coerce")
                    if s.notna().sum() > 0:
                        cand = col
                        break
            if cand:
                dp = pd.to_numeric(d[cand], errors="coerce").dropna().to_numpy()
        except Exception:
            dp = None

    if dp is not None and dp.size >= 5:
        lo = float(np.percentile(dp, 5.0))
        hi = float(np.percentile(dp, 95.0))
        if hi - lo < 0.1:
            mid = 0.5 * (lo + hi)
            lo = max(0.0, mid - 0.25)
            hi = mid + 0.25
        fit_x = dp
        weights = None
    else:
        lo, hi = 2.0, 6.0
        fit_x = np.linspace(lo, hi, 400)
        weights = None

    y = K * np.sqrt(np.clip(fit_x, 0.0, None))
    m_rec, c_rec = _fit_linear_L2(fit_x, y, w=weights)

    cur = _compute_errors_over_band(K, m0 or 0.0, c0 or 0.0, lo, hi)
    rec = _compute_errors_over_band(K, m_rec, c_rec, lo, hi)
    dp_cross_cur = _solve_crossover(K, m0 or 0.0, c0 or 0.0)
    dp_cross_rec = _solve_crossover(K, m_rec, c_rec)

    blocks: list[list[str]] = []
    blocks.append([
        "Recommendations",
        "───────────────",
        f"Operating DP band used for fit: {lo:.3f} – {hi:.3f} mbar",
        f"Current 820: m = {m0 if m0 is not None else 'n/a'}  |  c = {c0 if c0 is not None else 'n/a'}",
        f"Recommended 820 (least-squares over band): m* = {m_rec:.4f}  |  c* = {c_rec:.4f}",
        f"Δm = {((m_rec-(m0 or 0.0))):+.4f}   Δc = {((c_rec-(c0 or 0.0))):+.4f}",
    ])
    blocks.append([
        "Expected tracking error over band (820 − UIC):",
        f"  Current:   mean |Δ| = {cur['mean_abs']:.3f} t/h   |   worst |Δ| = {cur['worst_abs']:.3f} t/h @ DP ≈ {cur['dp_at_worst']:.3f} mbar",
        f"  Proposed:  mean |Δ| = {rec['mean_abs']:.3f} t/h   |   worst |Δ| = {rec['worst_abs']:.3f} t/h @ DP ≈ {rec['dp_at_worst']:.3f} mbar",
    ])
    cross_line: list[str] = []
    if dp_cross_cur is not None:
        cross_line.append(f"Current crossover (820 = UIC): DP ≈ {dp_cross_cur:.3f} mbar")
    if dp_cross_rec is not None:
        cross_line.append(f"Proposed crossover (820 = UIC): DP ≈ {dp_cross_rec:.3f} mbar")
    if cross_line:
        blocks.append(cross_line)

    blocks.append([
        "Notes:",
        "  • The recommendation optimizes average tracking (least-squares).",
        "  • If you prefer to minimize worst-case error, set the band you care about tighter (e.g., interquartile DP) and re-run.",
        "  • Re-program the 820 with (m*, c*) for the season shown on the cover.",
    ])
    return _fig_text_page("Recommendations", blocks)


def _fig_per_port_table(per_port_csv: Path) -> plt.Figure | None:
    p = Path(per_port_csv)
    if not p.exists(): return None
    df = pd.read_csv(p)
    # Choose a compact subset if available
    prefer = [c for c in ["Port","VP_pa_mean","T_C_mean","Static_abs_pa_mean","q_s_pa","w_s","w_t"] if c in df.columns]
    view = df[prefer] if prefer else df
    fig = plt.figure(figsize=(11.69, 8.27))  # A4 landscape
    ax = fig.add_axes([0.03, 0.03, 0.94, 0.92]); ax.axis("off")
    ax.set_title("Per-port summary", loc="left")
    tbl = ax.table(cellText=view.values[:20], colLabels=view.columns, loc="center")
    tbl.auto_set_font_size(False); tbl.set_fontsize(8); tbl.scale(1.0, 1.2)
    return fig


def _fig_flow_reference_with_overlay(outdir: Path) -> plt.Figure | None:
    ref = Path(outdir) / "transmitter_lookup_reference.csv"
    if not ref.exists(): return None
    dref = pd.read_csv(ref)
    fig = plt.figure(figsize=(11.69, 8.27)); ax = fig.add_subplot(111)
    ax.plot(dref["ref_DP_mbar"], dref["ref_Flow_UIC_tph"], label="UIC (√DP) – reference")
    ax.plot(dref["ref_DP_mbar"], dref["ref_Flow_820_tph"], label="820 (linear) – reference")
    data = Path(outdir) / "transmitter_lookup_data.csv"
    if data.exists():
        dd = pd.read_csv(data)
        if {"data_DP_mbar","data_Flow_UIC_tph","data_Flow_820_tph"}.issubset(dd.columns):
            ax.scatter(dd["data_DP_mbar"], dd["data_Flow_UIC_tph"], s=12, alpha=0.7, label="UIC – data")
            ax.scatter(dd["data_DP_mbar"], dd["data_Flow_820_tph"], s=12, alpha=0.7, label="820 – data")
    ax.set_xlabel("DP (mbar)"); ax.set_ylabel("Flow (t/h)")
    ax.set_title("Flow lookup: reference (constant) with data overlay")
    ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    return fig


def _fig_flow_reference_zoom(outdir: Path) -> plt.Figure | None:
    """Same as the full plot, but X-zoomed to the overlay DP band (+ padding).
    Skips if no overlay data is present."""
    ref = Path(outdir) / "transmitter_lookup_reference.csv"
    data = Path(outdir) / "transmitter_lookup_data.csv"
    if not (ref.exists() and data.exists()):
        return None
    dref = pd.read_csv(ref)
    dd = pd.read_csv(data)
    need = {"data_DP_mbar", "data_Flow_UIC_tph", "data_Flow_820_tph"}
    if not need.issubset(dd.columns):
        return None
    dp = pd.to_numeric(dd["data_DP_mbar"], errors="coerce").dropna()
    if dp.empty:
        return None
    dp_min = float(dp.min()); dp_max = float(dp.max()); span = dp_max - dp_min
    pad = max(0.10 * span, 0.05)  # at least ±0.05 mbar
    lo = max(0.0, dp_min - pad)
    ref_max = float(dref["ref_DP_mbar"].max())
    hi = min(ref_max, dp_max + pad)
    if hi <= lo:
        return None
    zr = dref[(dref["ref_DP_mbar"] >= lo) & (dref["ref_DP_mbar"] <= hi)]
    fig = plt.figure(figsize=(11.69, 8.27)); ax = fig.add_subplot(111)
    ax.plot(zr["ref_DP_mbar"], zr["ref_Flow_UIC_tph"], label="UIC (√DP) – reference", zorder=1)
    ax.plot(zr["ref_DP_mbar"], zr["ref_Flow_820_tph"], label="820 (linear) – reference", zorder=1)
    ax.scatter(dd["data_DP_mbar"], dd["data_Flow_UIC_tph"], s=20, alpha=0.85, label="UIC – data", zorder=5)
    ax.scatter(dd["data_DP_mbar"], dd["data_Flow_820_tph"], s=20, alpha=0.85, label="820 – data", zorder=5)
    ax.set_xlim(lo, hi)
    ax.set_xlabel("DP (mbar)"); ax.set_ylabel("Flow (t/h)")
    # Title plus Piccolo current band if range is known
    title = f"Flow lookup — overlay zoom (n={len(dp)}, DP {dp_min:.3f}–{dp_max:.3f} mbar)"
    rng = I_lo = I_hi = None
    try:
        s_all = _load_json(Path(outdir) / "summary.json")
        rng = (s_all.get("piccolo_info") or {}).get("range_mbar", None)
        if rng and rng > 0:
            I_lo = 4.0 + 16.0 * (dp_min / float(rng))
            I_hi = 4.0 + 16.0 * (dp_max / float(rng))
            title += f"\n(Piccolo range {rng:.3f} mbar → I {I_lo:.4f}–{I_hi:.4f} mA)"
    except Exception:
        pass
    ax.set_title(title)
    ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    if I_lo is not None and I_hi is not None:
        fig.text(0.5, 0.03, f"Implied Piccolo I from overlay DP: {I_lo:.4f}–{I_hi:.4f} mA", ha="center", fontsize=10)
    return fig


def _fig_venturi_curve(outdir: Path) -> plt.Figure | None:
    curve_csv = Path(outdir) / "venturi_curve.csv"
    vjson = Path(outdir) / "venturi_result.json"
    df = None
    if curve_csv.exists():
        df = pd.read_csv(curve_csv)
    elif vjson.exists():
        try:
            v = json.loads(vjson.read_text())
            df = pd.DataFrame(v.get("curve", []))
        except Exception:
            df = None
    if df is None or not {"frac_of_Qs","dp_vent_Pa"}.issubset(df.columns):
        return None
    fig = plt.figure(figsize=(11.69, 8.27))
    ax = fig.add_subplot(111)
    ax.plot(df["frac_of_Qs"], df["dp_vent_Pa"], marker="o")
    ax.set_xlabel("Fraction of Qs"); ax.set_ylabel("Venturi Δp (Pa)")
    ax.set_title("Venturi Δp vs Flow"); ax.grid(True, linestyle="--", alpha=0.4)
    return fig


def _fig_setpoints(outdir: Path) -> plt.Figure | None:
    csv = Path(outdir) / "transmitter_setpoints.csv"
    if not csv.exists(): return None
    df = pd.read_csv(csv)
    needed = {"UIC_percent","Y820"}
    if not needed.issubset(df.columns): return None
    fig = plt.figure(figsize=(11.69, 8.27))
    ax = fig.add_subplot(111)
    ax.plot(df.index, df["UIC_percent"], label="UIC %")
    ax.plot(df.index, df["Y820"], label="820")
    ax.set_xlabel("Sample index"); ax.set_ylabel("Output")
    ax.set_title("Transmitter outputs (from logger)"); ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    return fig


def build_run_report_pdf(
    outdir: Path,
    summary_path: Path,
    filename: str = "RunReport.pdf",
) -> Path:
    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)
    pdf_path = outdir / filename
    with PdfPages(pdf_path) as pdf:
        # Cover
        pdf.savefig(_fig_cover(outdir, summary_path)); plt.close()
        # Executive summary
        f = _exec_summary(outdir, summary_path)
        if f: pdf.savefig(f); plt.close()
        # Context & Method
        f = _context_and_method(outdir, summary_path)
        if f: pdf.savefig(f); plt.close()
        # Recommendations
        f = _recommendations_page(outdir, summary_path)
        if f: pdf.savefig(f); plt.close()
        # Per-port table
        f = _fig_per_port_table(outdir / "per_port.csv")
        if f: pdf.savefig(f); plt.close()
        # Flow reference (constant) + data overlay (optional)
        f = _fig_flow_reference_with_overlay(outdir)
        if f: pdf.savefig(f); plt.close()
        # Flow reference + overlay (zoomed to overlay region)
        f = _fig_flow_reference_zoom(outdir)
        if f: pdf.savefig(f); plt.close()
        # Venturi curve (optional)
        f = _fig_venturi_curve(outdir)
        if f: pdf.savefig(f); plt.close()
        # Setpoints plot (optional)
        f = _fig_setpoints(outdir)
        if f: pdf.savefig(f); plt.close()
    return pdf_path


__all__ = ["build_run_report_pdf"]

