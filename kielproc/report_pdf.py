from __future__ import annotations
from matplotlib.backends.backend_pdf import PdfPages
import json, math, textwrap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from pathlib import Path


def _load_json(p: Path) -> dict:
    try:
        return json.loads(Path(p).read_text())
    except Exception:
        return {}


def _fig_text(title: str, lines: list[str]) -> plt.Figure:
    """Text page with safe ASCII, consistent wrap and readable padding."""
    fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait
    ax = fig.add_axes([0,0,1,1]); ax.axis("off")
    y = 0.94
    left_margin = 0.07
    wrap_width = 80  # tighter to avoid edge spill
    ax.text(left_margin, y, title, va="top", ha="left", fontsize=14, weight="bold")
    y -= 0.044
    for raw in lines:
        # normalize risky glyphs to ASCII so PDF text never drops them
        safe = (raw.replace("√", "sqrt")
                    .replace("·", "*")
                    .replace("Δ", "d")
                    .replace("ρ", "rho"))
        wrapped = textwrap.fill(safe, width=wrap_width)
        ax.text(left_margin, y, wrapped, va="top", ha="left",
                fontsize=10, family="monospace")
        y -= 0.034 + 0.014 * max(1, wrapped.count("\n")+1)
        if y < 0.08:
            break
    return fig


def _fig_cover(outdir: Path, summary_path: Path) -> plt.Figure:
    s = {}
    try:
        s = json.loads(Path(summary_path).read_text())
    except Exception:
        pass
    meta_path = Path(outdir) / "transmitter_lookup_meta.json"
    flow_meta = {}
    try:
        flow_meta = json.loads(meta_path.read_text())
    except Exception:
        pass

    fig = plt.figure(figsize=(8.27, 11.69))  # A4 portrait
    ax = fig.add_axes([0,0,1,1]); ax.axis("off")
    lines = []
    lines.append("KielProc — Mill PA Differential Validation Report")
    lines.append("")
    lines.append(f"Generated: {datetime.now().isoformat(timespec='seconds')}")
    if s:
        lines.append(f"Site: {s.get('site_name','')}")
        bp = s.get("baro_pa", None)
        if isinstance(bp, (int, float)): lines.append(f"Barometric pressure: {bp:.0f} Pa")
        lines.append(f"Input mode: {s.get('input_mode','')}")
        lines.append(f"Prepared input: {s.get('prepared_input_dir','')}")
        if s.get("beta") is not None or s.get("r") is not None:
            lines.append(f"β: {s.get('beta')}    r: {s.get('r')}")
    if flow_meta:
        cal = flow_meta.get("calibration", {})
        lines.append("")
        lines.append(f"Season: {flow_meta.get('season','')}")
        if cal:
            lines.append(f"UIC K (t/h per sqrt(mbar)): {cal.get('K_uic','')}")
            lines.append(f"820 m (t/h/mbar): {cal.get('m_820','')}   c (t/h): {cal.get('c_820','')}")
            lines.append(f"Calibration source: {cal.get('source','')}")
    ax.text(0.08, 0.92, "\n".join(lines), va="top", ha="left", fontsize=12, family="monospace")
    ax.text(0.08, 0.06, "Generated by kielproc.run_easy.run_all()", fontsize=9)
    return fig


def _summary_merged(outdir: Path, summary_path: Path) -> plt.Figure:
    """
    One compact page: Summary + Context & Method + Recommendations.
    Also fixes Piccolo mapping to multi-line bullets so it never overflows.
    """
    s = _load_json(summary_path)
    meta = _load_json(Path(outdir) / "transmitter_lookup_meta.json")

    # Calibration / season
    season = meta.get("season", "")
    cal = meta.get("calibration", {}) or {}
    K = cal.get("K_uic", None); m = cal.get("m_820", None); c = cal.get("c_820", None)
    baro = _load_json(summary_path).get("baro_pa", None)
    baro_line = f"{baro:.0f} Pa" if isinstance(baro, (int,float)) else "n/a"

    # ---------- Overlay stats ----------
    overlay_csv = meta.get("overlay_csv")
    n = 0; dp_min = dp_max = None; mean_abs = worst_abs = None
    df = None
    if overlay_csv and Path(overlay_csv).exists():
        try:
            dd = pd.read_csv(Path(outdir) / "transmitter_lookup_combined.csv")
        except Exception:
            try:
                dd = pd.read_csv(Path(overlay_csv))
            except Exception:
                dd = None
        if isinstance(dd, pd.DataFrame) and {"data_DP_mbar","data_Flow_UIC_tph","data_Flow_820_tph"}.issubset(dd.columns):
            df = dd.dropna(subset=["data_DP_mbar","data_Flow_UIC_tph","data_Flow_820_tph"])
            if not df.empty:
                n = int(df.shape[0])
                dp_min = float(df["data_DP_mbar"].min())
                dp_max = float(df["data_DP_mbar"].max())
                err = (df["data_Flow_820_tph"] - df["data_Flow_UIC_tph"]).to_numpy()
                mean_abs = float(np.nanmean(np.abs(err)))
                worst_abs = float(np.nanmax(np.abs(err)))

    # crossover DP (informative)
    dp_cross = None
    try:
        if all(isinstance(v,(int,float)) for v in [K,m,c]) and K>0 and m>0:
            A = (m*m); B = (2*m*c - K*K); Cq = (c*c)
            disc = B*B - 4*A*Cq
            if disc >= 0:
                r1 = (-B + math.sqrt(disc)) / (2*A)
                r2 = (-B - math.sqrt(disc)) / (2*A)
                for r in (r1, r2):
                    if r and r > 0: dp_cross = float(r); break
    except Exception:
        pass

    # ---------- Recommendations (ideal local linearization over band) ----------
    def _fit_linear_L2(x, y):
        x = np.asarray(x, float); y = np.asarray(y, float)
        if x.size < 2:
            xm = float(np.nanmedian(x)) if x.size else 1.0
            ym = float(np.nanmedian(y)) if x.size else 0.0
            m_ = 0.0 if xm <= 0 else (ym/(2.0*xm)); c_ = ym - m_*xm
            return float(max(m_,0.0)), float(max(c_,0.0))
        X = np.c_[x, np.ones_like(x)]
        m_, c_ = np.linalg.lstsq(X, y, rcond=None)[0]
        return float(max(m_,0.0)), float(max(c_,0.0))

    # operating band from overlay if available, else default
    if n > 0 and df is not None:
        lo = float(np.percentile(df["data_DP_mbar"], 5.0))
        hi = float(np.percentile(df["data_DP_mbar"], 95.0))
        if hi - lo < 1e-6:
            hi = lo + 0.2
    else:
        lo, hi = 2.0, 6.0
    lo = max(1e-6, lo); hi = max(lo+1e-6, hi)
    mid = 0.5*(lo+hi)

    # reference function and helpers
    K0 = float(K or 0.0)
    def f(dp): return K0 * np.sqrt(np.clip(dp, 0.0, None))
    def fprime(dp): return (0.0 if dp <= 0 else K0 / (2.0*np.sqrt(dp)))

    # Tangent at DP_mid
    m_tan = fprime(mid)
    c_tan = f(mid) - m_tan*mid

    # Secant across [lo,hi]
    m_sec = (f(hi) - f(lo)) / (hi - lo)
    c_sec = f(lo) - m_sec*lo

    # L2 over band (uniform)
    gx = np.linspace(lo, hi, 800)
    yx = f(gx)
    m_l2, c_l2 = _fit_linear_L2(gx, yx)

    # Minimax (L∞) over band: 1D search over slope; optimal c centers sup error
    m_min = fprime(hi)  # smallest slope in band
    m_max = fprime(lo)  # largest slope in band
    m_grid = np.linspace(m_min, m_max, 400)
    def extremal_g(mv):
        # g(x) = m*x - f(x); extrema at lo, hi, and where f'(x)=m
        xstar = (K0/(2.0*mv))**2 if (mv > 0 and K0 > 0) else None
        xs = [lo, hi]
        if xstar is not None and lo <= xstar <= hi:
            xs.append(xstar)
        gvals = [mv*x - f(x) for x in xs]
        return xs[int(np.argmax(gvals))], xs[int(np.argmin(gvals))], float(np.max(gvals)), float(np.min(gvals))
    best = {"t": np.inf, "m": None, "c": None, "x_pos": None, "x_neg": None}
    for mv in m_grid:
        xp, xn, gp, gn = extremal_g(mv)
        # choose c to center sup error: max(e)= -min(e) -> c = - (gmax + gmin)/2
        cv = -0.5*(gp + gn)
        t = 0.5*(gp - gn)  # minimized sup |e|
        if t < best["t"]:
            best.update({"t": t, "m": float(mv), "c": float(cv), "x_pos": xp, "x_neg": xn})
    # refine around best slope
    if best["m"] is not None:
        m_lo = max(m_min, best["m"] - 0.1*(m_max-m_min))
        m_hi = min(m_max, best["m"] + 0.1*(m_max-m_min))
        for mv in np.linspace(m_lo, m_hi, 200):
            xp, xn, gp, gn = extremal_g(mv)
            cv = -0.5*(gp + gn); t = 0.5*(gp - gn)
            if t < best["t"]:
                best.update({"t": t, "m": float(mv), "c": float(cv), "x_pos": xp, "x_neg": xn})
    m_inf = float(best["m"]) if best["m"] is not None else m_l2
    c_inf = float(best["c"]) if best["c"] is not None else c_l2

    # error metrics (uniform grid on band)
    def _band_err(K_, m_, c_, lo_, hi_):
        gx = np.linspace(max(0.0, lo_), max(lo_, hi_), 1000)
        e = (m_*gx + c_) - (K_*np.sqrt(gx))
        return float(np.nanmean(np.abs(e))), float(np.nanmax(np.abs(e))), float(gx[int(np.nanargmax(np.abs(e)))])
    cur_mean, cur_worst, cur_wdp = _band_err(K0, float(m or 0.0), float(c or 0.0), lo, hi)
    tan_mean, tan_worst, tan_wdp = _band_err(K0, m_tan, c_tan, lo, hi)
    sec_mean, sec_worst, sec_wdp = _band_err(K0, m_sec, c_sec, lo, hi)
    l2_mean,  l2_worst,  l2_wdp  = _band_err(K0, m_l2,  c_l2,  lo, hi)
    inf_mean, inf_worst, inf_wdp = _band_err(K0, m_inf, c_inf, lo, hi)
    # recommended = minimax
    m_rec, c_rec = m_inf, c_inf

    def _cross(K_, m_, c_):
        try:
            A = m_*m_; B = 2*m_*c_ - K_*K_; Cq = c_*c_
            disc = B*B - 4*A*Cq
            if disc < 0: return None
            r1 = (-B + math.sqrt(disc))/(2*A); r2 = (-B - math.sqrt(disc))/(2*A)
            for r in (r1, r2):
                if r and r > 0: return float(r)
        except Exception: return None
        return None
    cross_rec = _cross(K0, m_rec, c_rec)

    # ---------- Build one compact page ----------
    # (header "Summary" provided separately by _fig_text)
    L: list[str] = []
    Ktxt = f"{K:.4f} t/h per sqrt(mbar)" if isinstance(K,(int,float)) else "n/a"
    L.append("Season: {}   Calibration: K(UIC)={}   m(820)={}   c(820)={}"\
             .format(season or "n/a", Ktxt,
                     m if m is not None else "n/a",
                     c if c is not None else "n/a"))
    L.append(f"Site: {s.get('site_name','')}")
    L.append(f"Barometric pressure: {baro_line}")
    # Temperature & density (if present)
    T_K_val = s.get("T_K")
    rho_val = s.get("rho_kg_m3")
    rho_src = s.get("rho_source")
    if isinstance(T_K_val, (int, float)):
        L.append(f"Process temperature: {T_K_val:.2f} K ({T_K_val-273.15:.1f} C)")
    if isinstance(rho_val, (int, float)):
        line = f"rho used: {rho_val:.4f} kg/m3"
        if rho_src:
            line += f"  [{rho_src}]"
        if rho_val < 0.2 or rho_val > 2.0:
            line += "  (WARNING: implausible -- check baro/T units)"
        L.append(line)
    if n > 0:
        L.append("")  # spacer
        L.append("Overlay (Piccolo-derived DP):")
        L.append(f"  • Samples: n={n}")
        L.append(f"  • DP band: {dp_min:.3f}–{dp_max:.3f} mbar")
        L.append(f"  • 820 vs UIC: mean abs error = {mean_abs:.3f} t/h; worst abs = {worst_abs:.3f} t/h")
        L.append("Piccolo mapping:")
        pic = (s.get('piccolo_info') or {})
        rng = pic.get('range_mbar', None)
        avgI = pic.get('avg_current_mA', None)
        impliedI = None
        if rng and dp_min is not None and dp_max is not None and rng > 0:
            I_lo = 4.0 + 16.0 * (dp_min / float(rng))
            I_hi = 4.0 + 16.0 * (dp_max / float(rng))
            impliedI = (I_lo, I_hi)
        if rng is not None:
            L.append(f"  • Range: {rng:.3f} mbar")
        if avgI is not None:
            L.append(f"  • Average current (workbook): {avgI:.4f} mA")
        if impliedI:
            L.append(f"  • Implied current from overlay DP: {impliedI[0]:.4f}–{impliedI[1]:.4f} mA")
    else:
        L.append("Overlay: not present (reference curves only).")
    if dp_cross is not None:
        L.append(f"Crossover (current 820 = UIC): DP ≈ {dp_cross:.3f} mbar")
    L.append("")  # spacer
    L.append("Context & Method:")
    L.append("  • UIC (physics):  Flow_UIC = K*sqrt(DP)")
    L.append("  • 820 (linear):   Flow_820 = m*DP + c")
    L.append("  • Overlay DP from Piccolo 4–20 mA; baro from workbook when available.")
    L.append("")  # spacer
    L.append("Recommendations (local linearization over operating band):")
    L.append(f"  • Band: {lo:.3f}–{hi:.3f} mbar   (mid {mid:.3f})")
    L.append(f"  • Current 820: m={m if m is not None else 'n/a'}  c={c if c is not None else 'n/a'}")
    L.append(
        f"  • Proposed 820 (minimax L_inf): m*={m_rec:.4f}  c*={c_rec:.4f}  "
        f"(dm={(m_rec-(m or 0.0)):+.4f}  dc={(c_rec-(c or 0.0)):+.4f})"
    )
    L.append(f"    Errors — Current: mean={cur_mean:.3f}, worst={cur_worst:.3f} @ {cur_wdp:.3f} mbar")
    L.append(f"              L_inf:  mean={inf_mean:.3f}, worst={inf_worst:.3f} @ {inf_wdp:.3f} mbar")
    L.append(f"    Alternatives — Tangent@mid: m={m_tan:.4f}  c={c_tan:.4f}  (worst={tan_worst:.3f})")
    L.append(f"                   Secant:      m={m_sec:.4f}  c={c_sec:.4f}  (worst={sec_worst:.3f})")
    L.append(f"                   L2:          m={m_l2:.4f}  c={c_l2:.4f}    (worst={l2_worst:.3f})")
    if cross_rec is not None:
        L.append(f"  • Proposed crossover (820 = UIC): DP ≈ {cross_rec:.3f} mbar")
    return _fig_text("Summary", L)


def _fig_per_port_table(per_port_csv: Path) -> plt.Figure | None:
    p = Path(per_port_csv)
    if not p.exists(): return None
    df = pd.read_csv(p)
    # Choose a compact subset if available
    prefer = [c for c in ["Port","VP_pa_mean","T_C_mean","Static_abs_pa_mean","q_s_pa","w_s","w_t"] if c in df.columns]
    view = df[prefer] if prefer else df
    fig = plt.figure(figsize=(11.69, 8.27))  # A4 landscape
    ax = fig.add_axes([0.03, 0.03, 0.94, 0.92]); ax.axis("off")
    ax.set_title("Per-port summary", loc="left")
    tbl = ax.table(cellText=view.values[:20], colLabels=view.columns, loc="center")
    tbl.auto_set_font_size(False); tbl.set_fontsize(8); tbl.scale(1.0, 1.2)
    return fig


def _fig_flow_reference_with_overlay(outdir: Path) -> plt.Figure | None:
    ref = Path(outdir) / "transmitter_lookup_reference.csv"
    if not ref.exists(): return None
    dref = pd.read_csv(ref)
    fig = plt.figure(figsize=(11.69, 8.27)); ax = fig.add_subplot(111)
    ax.plot(dref["ref_DP_mbar"], dref["ref_Flow_UIC_tph"], label="UIC (√DP) – reference")
    ax.plot(dref["ref_DP_mbar"], dref["ref_Flow_820_tph"], label="820 (linear) – reference")
    data = Path(outdir) / "transmitter_lookup_data.csv"
    if data.exists():
        dd = pd.read_csv(data)
        if {"data_DP_mbar","data_Flow_UIC_tph","data_Flow_820_tph"}.issubset(dd.columns):
            ax.scatter(dd["data_DP_mbar"], dd["data_Flow_UIC_tph"], s=12, alpha=0.7, label="UIC – data")
            ax.scatter(dd["data_DP_mbar"], dd["data_Flow_820_tph"], s=12, alpha=0.7, label="820 – data")
    ax.set_xlabel("DP (mbar)"); ax.set_ylabel("Flow (t/h)")
    ax.set_title("Flow lookup: reference (constant) with data overlay")
    ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    return fig


def _fig_flow_reference_zoom(outdir: Path) -> plt.Figure | None:
    """Same as the full plot, but X-zoomed to the overlay DP band (+ padding).
    Skips if no overlay data is present."""
    ref = Path(outdir) / "transmitter_lookup_reference.csv"
    data = Path(outdir) / "transmitter_lookup_data.csv"
    if not (ref.exists() and data.exists()):
        return None
    dref = pd.read_csv(ref)
    dd = pd.read_csv(data)
    need = {"data_DP_mbar", "data_Flow_UIC_tph", "data_Flow_820_tph"}
    if not need.issubset(dd.columns):
        return None
    dp = pd.to_numeric(dd["data_DP_mbar"], errors="coerce").dropna()
    if dp.empty:
        return None
    dp_min = float(dp.min()); dp_max = float(dp.max()); span = dp_max - dp_min
    pad = max(0.10 * span, 0.05)  # at least ±0.05 mbar
    lo = max(0.0, dp_min - pad)
    ref_max = float(dref["ref_DP_mbar"].max())
    hi = min(ref_max, dp_max + pad)
    if hi <= lo:
        return None
    zr = dref[(dref["ref_DP_mbar"] >= lo) & (dref["ref_DP_mbar"] <= hi)]
    fig = plt.figure(figsize=(11.69, 8.27)); ax = fig.add_subplot(111)
    ax.plot(zr["ref_DP_mbar"], zr["ref_Flow_UIC_tph"], label="UIC (√DP) – reference", zorder=1)
    ax.plot(zr["ref_DP_mbar"], zr["ref_Flow_820_tph"], label="820 (linear) – reference", zorder=1)
    ax.scatter(dd["data_DP_mbar"], dd["data_Flow_UIC_tph"], s=20, alpha=0.85, label="UIC – data", zorder=5)
    ax.scatter(dd["data_DP_mbar"], dd["data_Flow_820_tph"], s=20, alpha=0.85, label="820 – data", zorder=5)
    ax.set_xlim(lo, hi)
    ax.set_xlabel("DP (mbar)"); ax.set_ylabel("Flow (t/h)")
    # Title plus Piccolo current band if range is known
    title = f"Flow lookup — overlay zoom (n={len(dp)}, DP {dp_min:.3f}–{dp_max:.3f} mbar)"
    rng = I_lo = I_hi = None
    try:
        s_all = _load_json(Path(outdir) / "summary.json")
        rng = (s_all.get("piccolo_info") or {}).get("range_mbar", None)
        if rng and rng > 0:
            I_lo = 4.0 + 16.0 * (dp_min / float(rng))
            I_hi = 4.0 + 16.0 * (dp_max / float(rng))
            title += f"\n(Piccolo range {rng:.3f} mbar → I {I_lo:.4f}–{I_hi:.4f} mA)"
    except Exception:
        pass
    ax.set_title(title)
    ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    if I_lo is not None and I_hi is not None:
        fig.text(0.5, 0.03, f"Implied Piccolo I from overlay DP: {I_lo:.4f}–{I_hi:.4f} mA", ha="center", fontsize=10)
    return fig


def _fig_venturi_curve(outdir: Path) -> plt.Figure | None:
    """
    Venturi Δp vs Mass Flow with explicit units and on-plot metadata.
    """
    outdir = Path(outdir)
    vr = outdir / "venturi_result.json"
    dr = outdir / "duct_result.json"
    flow_kg_s = None; dp_pa = None
    beta = None; A1 = None; At = None; rho = None
    if vr.exists():
        d = json.loads(vr.read_text())
        flow_kg_s = np.asarray(d.get("flow_kg_s") or d.get("flow"), float)
        dp_pa     = np.asarray(d.get("dp_pa") or d.get("delta_p_pa"), float)
        beta = d.get("beta"); A1 = d.get("A1_m2") or d.get("As_m2"); At = d.get("At_m2"); rho = d.get("rho_kg_m3")
    elif dr.exists():
        d = json.loads(dr.read_text())
        # Try to reconstruct curve if geometry is present
        beta = d.get("beta"); A1 = d.get("area_m2"); At = d.get("At_m2")
        if (beta is not None) and (A1 is not None) and (At is None):
            try: At = (float(beta)**2) * float(A1)
            except: pass
        rho = d.get("rho_kg_m3")
        m0  = d.get("m_dot_kg_s"); dp0 = d.get("delta_p_vent_est_pa")
        if (m0 and rho and At and beta and dp0):
            m0 = float(m0); rho = float(rho); At = float(At); beta = float(beta)
            flow_kg_s = np.linspace(max(0.1, 0.25*m0), 2.0*m0, 200)
            dp_pa = (1.0 - beta**4) * (flow_kg_s**2) / (2.0 * rho * (At**2))
        else:
            return None
    else:
        return None
    if flow_kg_s is None or dp_pa is None:
        return None
    flow_tph = flow_kg_s * 3.6
    fig = plt.figure(figsize=(11.69, 8.27)); ax = fig.add_subplot(111)
    ax.plot(flow_tph, dp_pa, label="Model: Δp = (1−β⁴)·ṁ²/(2·ρ·Aₜ²)")
    ax.set_title("Venturi Δp vs Mass Flow")
    ax.set_xlabel("Mass flow (t/h)")
    ax.set_ylabel("Venturi Δp (Pa)")
    ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    # On-plot metadata (geometry & density)
    meta = []
    if beta is not None: meta.append(f"β = {float(beta):.4f}")
    if A1   is not None: meta.append(f"A₁ = {float(A1):.4f} m²")
    if At   is not None: meta.append(f"Aₜ = {float(At):.4f} m²")
    if rho  is not None: meta.append(f"ρ = {float(rho):.4f} kg/m³")
    if meta:
        ax.text(0.98, 0.98, "\n".join(meta), ha="right", va="top", transform=ax.transAxes,
                fontsize=9, bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="0.6", alpha=0.9))
    if (rho is not None) and (rho < 0.2 or rho > 2.0):
        ax.text(0.02, 0.02, "WARNING: ρ looks implausible — check baro/T units",
                ha="left", va="bottom", transform=ax.transAxes, fontsize=9, color="crimson")
    return fig


def _fig_setpoints(outdir: Path) -> plt.Figure | None:
    csv = Path(outdir) / "transmitter_setpoints.csv"
    if not csv.exists(): return None
    df = pd.read_csv(csv)
    needed = {"UIC_percent","Y820"}
    if not needed.issubset(df.columns): return None
    fig = plt.figure(figsize=(11.69, 8.27))
    ax = fig.add_subplot(111)
    ax.plot(df.index, df["UIC_percent"], label="UIC %")
    ax.plot(df.index, df["Y820"], label="820")
    ax.set_xlabel("Sample index"); ax.set_ylabel("Output")
    ax.set_title("Transmitter outputs (from logger)"); ax.grid(True, linestyle="--", alpha=0.4); ax.legend()
    return fig


def build_run_report_pdf(
    outdir: Path,
    summary_path: Path,
    filename: str = "RunReport.pdf",
) -> Path:
    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)
    pdf_path = outdir / filename
    with PdfPages(pdf_path) as pdf:
        # Cover
        pdf.savefig(_fig_cover(outdir, summary_path)); plt.close()
        # Single merged page (Summary + Context & Method + Recommendations)
        f = _summary_merged(outdir, summary_path)
        if f: pdf.savefig(f); plt.close()
        # Per-port table
        f = _fig_per_port_table(outdir / "per_port.csv")
        if f: pdf.savefig(f); plt.close()
        # Flow reference (constant) + data overlay (optional)
        f = _fig_flow_reference_with_overlay(outdir)
        if f: pdf.savefig(f); plt.close()
        # Flow reference + overlay (zoomed to overlay region)
        f = _fig_flow_reference_zoom(outdir)
        if f: pdf.savefig(f); plt.close()
        # Venturi curve (optional)
        f = _fig_venturi_curve(outdir)
        if f: pdf.savefig(f); plt.close()
        # Setpoints plot (optional)
        f = _fig_setpoints(outdir)
        if f: pdf.savefig(f); plt.close()
    return pdf_path


__all__ = ["build_run_report_pdf"]

